{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6582c662-40a4-4b33-ad12-751dbba314c3",
   "metadata": {},
   "source": [
    "# Commodity Sales Dashboard\n",
    "<https://public.tableau.com/app/profile/sieger.bokschoten/viz/USDACensusandAgricultureLabor/CommoditySalesDashboard>\n",
    "\n",
    "The only dependency required is pandas which can be installed with pip install pandas, or in a conda environment conda install pandas.\n",
    "\n",
    "The data source is the NASS USDA 2022 Census, which can be downloaded here: https://www.nass.usda.gov/datasets/qs.census2022.txt.gz\n",
    "The file will need to be unzipped and placed in the folder you will be using for your project.\n",
    "\n",
    "The census text file is a tab-separated text file, and uncompressed is around 2.2 GB. It's normal for the first command below to take 20 seconds or more to load the full dataset to memory.\n",
    "\n",
    "In this document I'm not going very in depth to how to decide which columns to filter, or what values will be contained in those columns, the reason is because before developing this documentation, I was exploring the data using the Spyder IDE. It has a useful variable explorer and IPython built in. If you want to explore the data yourself, I recommend using an IDE to walk through these steps and view the output. I'm skipping the data exploration steps because the full process is longer and documenting the process in Jupyter Notebooks is time consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2eff7ab-62dd-411a-8f1c-8bb006942fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_table('qs.census2022.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9d68fe-91c8-4ffa-a098-2a717cb249a1",
   "metadata": {},
   "source": [
    "Next, we'll take a quick look at the data types to make sure the dataframe was loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9880b177-839b-40e5-8708-f4695b67044b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOURCE_DESC               object\n",
      "SECTOR_DESC               object\n",
      "GROUP_DESC                object\n",
      "COMMODITY_DESC            object\n",
      "CLASS_DESC                object\n",
      "PRODN_PRACTICE_DESC       object\n",
      "UTIL_PRACTICE_DESC        object\n",
      "STATISTICCAT_DESC         object\n",
      "UNIT_DESC                 object\n",
      "SHORT_DESC                object\n",
      "DOMAIN_DESC               object\n",
      "DOMAINCAT_DESC            object\n",
      "AGG_LEVEL_DESC            object\n",
      "STATE_ANSI               float64\n",
      "STATE_FIPS_CODE            int64\n",
      "STATE_ALPHA               object\n",
      "STATE_NAME                object\n",
      "ASD_CODE                 float64\n",
      "ASD_DESC                  object\n",
      "COUNTY_ANSI              float64\n",
      "COUNTY_CODE              float64\n",
      "COUNTY_NAME               object\n",
      "REGION_DESC              float64\n",
      "ZIP_5                    float64\n",
      "WATERSHED_CODE             int64\n",
      "WATERSHED_DESC           float64\n",
      "CONGR_DISTRICT_CODE      float64\n",
      "COUNTRY_CODE               int64\n",
      "COUNTRY_NAME              object\n",
      "LOCATION_DESC             object\n",
      "YEAR                       int64\n",
      "FREQ_DESC                 object\n",
      "BEGIN_CODE                 int64\n",
      "END_CODE                   int64\n",
      "REFERENCE_PERIOD_DESC     object\n",
      "WEEK_ENDING              float64\n",
      "LOAD_TIME                 object\n",
      "VALUE                     object\n",
      "CV_%                      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ddd5ed-073f-479b-8764-c4fc205fb3d1",
   "metadata": {},
   "source": [
    "Now that we have the dataframe loaded we will need to start filtering rows so we reduce the size of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85e375ae-f188-495b-a862-fdeac684f3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = df[df['SECTOR_DESC'] == 'CROPS']\n",
    "sales = sales[sales['STATISTICCAT_DESC'] == 'SALES']\n",
    "sales = sales[sales['UNIT_DESC'] == '$']\n",
    "sales = sales[sales['DOMAIN_DESC'] == 'TOTAL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2289e476-70f6-44b9-87fc-2c762409772a",
   "metadata": {},
   "source": [
    "Now we need to remove all rows that are not counties, otherwise the data will be strongly skewed because the dataset is currently including US totals and state totals. Then we'll sort the data by state and county names and reindex. On the rows where STATE_NAME is nan, the total will refer to the US total. On the COUNTY_NAME rows where county is nan, the total will refer to either the state total, or the US total. We can remove both state totals, and US totals by only returning rows where COUNTY_NAME is not NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "752dca0b-e747-481a-9e2d-1842f334f80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = sales[sales['COUNTY_NAME'].notna()]\n",
    "sales.sort_values(by=['STATE_NAME', 'COUNTY_NAME'], inplace=True)\n",
    "sales = sales.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0337e578-948d-4259-af3e-e910d334aaf7",
   "metadata": {},
   "source": [
    "The next step is to change the 'VALUE' column datatype to Int64. Currently it's an object in Pandas, or a string with other software. This column currently contains comma seperated numbers to represent dollars in sales, and it contains the values '(D)' and '(Z)' which represent values that cannot be reported. Beacause we can't compare the values of columns with '(D)' or '(Z)', and those are not equal to zero, we'll convert them to NaN, so they don't affect any calculations. If you were to add these numbers up and compare to state totals, it's likely that they won't match up correctly, this is most likely because the USDA has access to the '(D)' or '(Z)' values, and so can add them to the final state totals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8439ab7-1eeb-4e9d-926b-ee61ee1bffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['VALUE'] = sales['VALUE'].str.replace(',', '')\n",
    "sales['VALUE'] = pd.to_numeric(sales['VALUE'], errors='coerce')\n",
    "sales['VALUE'] = sales['VALUE'].astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c68d7bb-d5ff-4b71-821c-a1129839c55c",
   "metadata": {},
   "source": [
    "We can verify that the column was converted succesfully by running the below command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8c94c1f-498b-4a7b-94a7-469aff171fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Dtype()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['VALUE'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcc86b5-7bbf-4392-8a05-02291d2bab59",
   "metadata": {},
   "source": [
    "The final steps are to remove unused columns, keeping only those that we may use for visualizations, then we export the file as a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0505eb9-34a5-4d8b-b548-6ada2eb8d077",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = sales[['STATE_NAME', 'STATE_ALPHA', 'COUNTY_NAME', 'GROUP_DESC', 'COMMODITY_DESC', 'SHORT_DESC', 'VALUE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ebddd2b-2d5b-467b-bc56-ee83650afaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATE_NAME        object\n",
      "STATE_ALPHA       object\n",
      "COUNTY_NAME       object\n",
      "GROUP_DESC        object\n",
      "COMMODITY_DESC    object\n",
      "SHORT_DESC        object\n",
      "VALUE              Int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(sales.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f122a7e2-5a1e-4b04-89d5-9002bf3b7807",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.to_csv('Commodity_Sales.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
